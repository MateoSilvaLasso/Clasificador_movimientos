{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.2-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\mateo\\appdata\\roaming\\python\\python312\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\mateo\\appdata\\roaming\\python\\python312\\site-packages (from xgboost) (1.14.1)\n",
      "Downloading xgboost-2.1.2-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.6/124.9 MB 16.7 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 5.8/124.9 MB 16.0 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 9.7/124.9 MB 16.8 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 14.7/124.9 MB 18.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 19.7/124.9 MB 20.0 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 24.9/124.9 MB 20.5 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 30.1/124.9 MB 21.0 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 35.9/124.9 MB 21.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 40.6/124.9 MB 21.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 45.9/124.9 MB 22.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 51.9/124.9 MB 22.8 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 58.7/124.9 MB 23.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 65.5/124.9 MB 24.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 71.8/124.9 MB 24.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 78.1/124.9 MB 25.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 85.7/124.9 MB 25.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 92.0/124.9 MB 26.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 99.1/124.9 MB 26.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 106.4/124.9 MB 26.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 113.2/124.9 MB 27.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 118.2/124.9 MB 27.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.9/124.9 MB 26.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 26.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 26.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 124.9/124.9 MB 24.6 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos(directorio):\n",
    "    data = []\n",
    "    etiquetas = []\n",
    "    for carpeta in os.listdir(directorio):\n",
    "        subdirectorio = os.path.join(directorio, carpeta, 'csv')\n",
    "        \n",
    "        for archivo in glob.glob(os.path.join(subdirectorio, '*.csv')):\n",
    "            df = pd.read_csv(archivo)\n",
    "            data.append(df)\n",
    "            etiquetas.append(carpeta)\n",
    "    return data, etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_coordenadas(df):\n",
    "    # Obtener las coordenadas promedio de las caderas\n",
    "    cadera_derecha = df[df['landmark_index'] == 23][['x', 'y', 'z']].mean()\n",
    "    cadera_izquierda = df[df['landmark_index'] == 24][['x', 'y', 'z']].mean()\n",
    "    cadera_centro = (cadera_derecha + cadera_izquierda) / 2\n",
    "    \n",
    "    # Normalizar restando las coordenadas de la cadera central\n",
    "    df['x'] -= cadera_centro['x']\n",
    "    df['y'] -= cadera_centro['y']\n",
    "    df['z'] -= cadera_centro['z']\n",
    "    \n",
    "    # Normalización por el tamaño del torso (distancia entre hombros 11 y 12)\n",
    "    hombro_derecho = df[df['landmark_index'] == 11][['x', 'y', 'z']].mean()\n",
    "    hombro_izquierdo = df[df['landmark_index'] == 12][['x', 'y', 'z']].mean()\n",
    "    torso_tamano = np.linalg.norm(hombro_derecho - hombro_izquierdo)\n",
    "    \n",
    "    df['x'] /= torso_tamano\n",
    "    df['y'] /= torso_tamano\n",
    "    df['z'] /= torso_tamano\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar las coordenadas\n",
    "def filtrar_datos(df):\n",
    "    df['x'] = gaussian_filter1d(df['x'], sigma=2)\n",
    "    df['y'] = gaussian_filter1d(df['y'], sigma=2)\n",
    "    df['z'] = gaussian_filter1d(df['z'], sigma=2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el ángulo entre tres puntos\n",
    "def calcular_angulo(p1, p2, p3):\n",
    "    vector1 = p1 - p2\n",
    "    vector2 = p3 - p2\n",
    "    cos_theta = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "    angulo = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n",
    "    return np.degrees(angulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de características agregadas\n",
    "def generar_caracteristicas(df):\n",
    "    # Articulaciones clave: hombros, codos, y caderas\n",
    "    articulaciones_clave = [11, 12, 13, 14, 15, 16, 23, 24]\n",
    "    \n",
    "    velocidades = []\n",
    "    angulos_codo_derecho = []\n",
    "    angulos_codo_izquierdo = []\n",
    "    angulos_tronco = []\n",
    "    \n",
    "    for i in range(1, len(df)):\n",
    "        fila_actual = df[df['frame'] == i]\n",
    "        fila_anterior = df[df['frame'] == i - 1]\n",
    "        \n",
    "        # Calcular velocidades\n",
    "        for articulacion in articulaciones_clave:\n",
    "            actual = fila_actual[fila_actual['landmark_index'] == articulacion]\n",
    "            anterior = fila_anterior[fila_anterior['landmark_index'] == articulacion]\n",
    "            \n",
    "            if not actual.empty and not anterior.empty:\n",
    "                vel_x = actual['x'].values[0] - anterior['x'].values[0]\n",
    "                vel_y = actual['y'].values[0] - anterior['y'].values[0]\n",
    "                vel_z = actual['z'].values[0] - anterior['z'].values[0]\n",
    "                velocidad = np.sqrt(vel_x**2 + vel_y**2 + vel_z**2)\n",
    "                velocidades.append(velocidad)\n",
    "\n",
    "        # Calcular ángulos\n",
    "        hombro_derecho = fila_actual[fila_actual['landmark_index'] == 11][['x', 'y', 'z']].values\n",
    "        codo_derecho = fila_actual[fila_actual['landmark_index'] == 13][['x', 'y', 'z']].values\n",
    "        muneca_derecha = fila_actual[fila_actual['landmark_index'] == 15][['x', 'y', 'z']].values\n",
    "        \n",
    "        if hombro_derecho.size > 0 and codo_derecho.size > 0 and muneca_derecha.size > 0:\n",
    "            angulo_codo_derecho = calcular_angulo(hombro_derecho[0], codo_derecho[0], muneca_derecha[0])\n",
    "            angulos_codo_derecho.append(angulo_codo_derecho)\n",
    "        \n",
    "        hombro_izquierdo = fila_actual[fila_actual['landmark_index'] == 12][['x', 'y', 'z']].values\n",
    "        codo_izquierdo = fila_actual[fila_actual['landmark_index'] == 14][['x', 'y', 'z']].values\n",
    "        muneca_izquierda = fila_actual[fila_actual['landmark_index'] == 16][['x', 'y', 'z']].values\n",
    "        \n",
    "        if hombro_izquierdo.size > 0 and codo_izquierdo.size > 0 and muneca_izquierda.size > 0:\n",
    "            angulo_codo_izquierdo = calcular_angulo(hombro_izquierdo[0], codo_izquierdo[0], muneca_izquierda[0])\n",
    "            angulos_codo_izquierdo.append(angulo_codo_izquierdo)\n",
    "        \n",
    "        cadera_centro = ((fila_actual[fila_actual['landmark_index'] == 23][['x', 'y', 'z']].values +\n",
    "                          fila_actual[fila_actual['landmark_index'] == 24][['x', 'y', 'z']].values) / 2)\n",
    "        \n",
    "        if hombro_derecho.size > 0 and cadera_centro.size > 0 and hombro_izquierdo.size > 0:\n",
    "            angulo_tronco = calcular_angulo(hombro_derecho[0], cadera_centro[0], hombro_izquierdo[0])\n",
    "            angulos_tronco.append(angulo_tronco)\n",
    "    \n",
    "    # Calcular estadísticas de cada característica\n",
    "    caracteristicas = [\n",
    "        np.mean(velocidades), np.std(velocidades),\n",
    "        np.mean(angulos_codo_derecho), np.std(angulos_codo_derecho),\n",
    "        np.mean(angulos_codo_izquierdo), np.std(angulos_codo_izquierdo),\n",
    "        np.mean(angulos_tronco), np.std(angulos_tronco)\n",
    "    ]\n",
    "    \n",
    "    return caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_y_extraer(data):\n",
    "    datos_procesados = []\n",
    "    for df in data:\n",
    "        df = normalizar_coordenadas(df)\n",
    "        df = filtrar_datos(df)\n",
    "        caracteristicas = generar_caracteristicas(df)\n",
    "        datos_procesados.append(caracteristicas)\n",
    "    return datos_procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "def entrenar_modelo(datos_procesados, etiquetas):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        datos_procesados, etiquetas, test_size=0.25, random_state=42,\n",
    "    )\n",
    "    \n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 250],\n",
    "        'max_depth': [100, 200, 300],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42, class_weight='balanced'), param_grid=param_grid, cv=skf, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(grid_search.best_params_)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "def guardar_modelo(modelo, nombre_archivo):\n",
    "    joblib.dump(modelo, nombre_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio_datos = 'datos'\n",
    "data, etiquetas = cargar_datos(directorio_datos)\n",
    "datos_procesados = preprocesar_y_extraer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mateo\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "             Sentarse       1.00      0.67      0.80         3\n",
      "  caminar hacia atras       1.00      0.83      0.91         6\n",
      "caminar hacia delante       1.00      1.00      1.00         2\n",
      "                girar       0.80      1.00      0.89         4\n",
      "              pararse       0.75      1.00      0.86         3\n",
      "\n",
      "             accuracy                           0.89        18\n",
      "            macro avg       0.91      0.90      0.89        18\n",
      "         weighted avg       0.91      0.89      0.89        18\n",
      "\n",
      "{'max_depth': 100, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "modelo = entrenar_modelo(datos_procesados, etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_modelo(modelo, 'modelo_clasificacion_actividades.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
